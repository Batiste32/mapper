# Database operations tools/functions
from sqlalchemy import create_engine, select, update, MetaData
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.engine.base import Engine

import csv
import bcrypt
import re # regex to cleanup data
from typing import Callable, Type
from rapidfuzz import process, fuzz
from pathlib import Path
from pandas import read_csv

from backend.utils.constants import *
from backend.database.schema import Base
from backend.database.models import Profile, User

def create_data_base(file_path:str = "backend/database/electoral_app.db"):
    "Generate a db file for SQLite."
    engine = create_engine(f"sqlite:///{Path(file_path)}", echo=True)
    Base.metadata.create_all(engine)
    print("Created database")
    return(engine)

def import_data_from_csv(engine: Engine, filepath: str = "backend/database/profiles.csv"):
    """
    Read a csv file to update the database.
    Requires the engine used to create the database and optionally the filepath.
    """
    Session = sessionmaker(bind=engine)
    session = Session()

    with open(filepath, newline='', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader :
            profile = Profile(
                uniqueid=row['UNIQUEID'],
                name=f"{row['FIRSTNAME']} {row['NAME']}",
                age=int(row['AGE']),
                nbhood=row['CIRCONSCRIPT'],  # Mapped as neighborhood
                score_vote=int(row['VOTE_PROBABILITY']) if row['VOTE_PROBABILITY'] else None,
                preferred_language=row['PREFERRED_LANGUAGE'],
                native_language=row['LANGUAGE'],
                origin=normalize_string_value(row['ORIGIN'],VALID_NATIONALITIES),
                political_lean=normalize_string_value(row['POLITICAL_LEANING'],VALID_LEANS),
                personality=isolate_stressed_elements_in_field(row['PERSONNALITY']),
                political_scale=row['POLITICAL_PROFILE'],
                ideal_process=row['INTERACTION_SEQUENCE'],
                strategic_profile=row['STRATEGIC_PROFILE'],
                suggested_arguments=row['SUGGESTED_ARGUMENTS'],
                picture_url="",
                distance=None
            )
            session.add(profile)

    session.commit()
    print("Imported profiles!")

def parse_database_field(table_name:str,fields:list[str],edits:list[Callable],database_path:str="backend/database/electoral_app.db"):
    """
    Edits rows in an SQLite database by applying transformation functions to specified fields.

    Args:
        table_name (str): Name of the table to modify.
        fields (list[str]): List of column names to modify.
        edits (list[callable]): List of functions to apply to each respective field.
        database_path (str): Path to the SQLite database file.
    """
    assert len(fields) == len(edits)

    engine = create_engine(f"sqlite:///{database_path}")
    metadata = MetaData()
    metadata.reflect(bind=engine)
    table = metadata.tables.get(table_name)

    if table is None :
        raise ValueError(f"Table '{table_name}' not found in database.")

    with Session(engine) as session :
        stmt = select(table)
        results = session.execute(stmt).fetchall()

        for row in results:
            row_dict = dict(row._mapping)
            updates = {}
            for field, edit_fn in zip(fields, edits):
                if field in row_dict:
                    original = row_dict[field]
                    updated = edit_fn(original)
                    if updated != original:
                        updates[field] = updated

            if updates:
                session.execute(
                    update(table)
                    .where(table.primary_key.columns.values()[0] == row_dict[table.primary_key.columns.keys()[0]])
                    .values(**updates)
                )

        session.commit()

def add_admin(engine:Engine, username:str, password:str):
    "Add an admin profile to the database. Requires the engine used to create the database and the credentials."
    Session = sessionmaker(bind=engine)
    session = Session()

    password_hash = bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())

    admin_user = User(username=username, password_hash=password_hash, is_admin=True)
    session.add(admin_user)
    session.commit()

    print(f"Admin user '{username}' created.")

def isolate_first_stressed_element_in_field(field: str):
    """
    Uses regex to extract first text inside ** ** or the whole field if not found.
    Cleans up the text fields generated by LLMs. 
    """
    regex_pattern = r'\*\*(.*?)\*\*'
    search = re.search(regex_pattern, field)
    if search:
        return search.group(1)
    else: 
        return field
    
def isolate_stressed_elements_in_field(field: str) -> str:
    """
    Extracts all substrings inside ** ** in the given field and returns them
    as a comma-separated string. Returns empty string if none found.
    """
    regex_pattern = r'\*\*(.*?)\*\*'
    matches = re.findall(regex_pattern, field)
    return ', '.join(matches) if matches else ''

def normalize_string_value(value: str, allowed_values: list[str], score_cutoff: int = 50, trim_at: int = 1) -> str:
    """
    Returns the closest allowed value using fuzzy matching.
    
    Args:
        value: The string to normalize.
        allowed_values: List of allowed canonical strings.
        score_cutoff: Minimum match score required to return a match.
        trim_at: Number of words to preserve before fitting.
        
    Returns:
        A cleaned/normalized string from allowed_values or the trimmed value if no match is close enough.
    """
    if not isinstance(value, str) or not value.strip() : # Avoid empty strings 
        return value
    
    if trim_at :
        words = value.split(' ')
        trimmed_value = ' '.join(words[:trim_at])
    else :
        trimmed_value = value
    match = process.extractOne(trimmed_value, allowed_values, scorer=fuzz.token_sort_ratio, score_cutoff=score_cutoff)
    if match :
        return match[0]
    else :
        print(f"[normalize_string_value] No match for '{trimmed_value}' (original: '{value}') among allowed values.")
        return trimmed_value

def reimport_column_from_csv(csv_path: str, csv_column_name:str, db_column_name: str, database_path: str):
    """
    Reimports a specific column from a CSV file and updates the corresponding
    rows in the database.

    Args:
        csv_path: Path to the CSV file.
        csv_column_name: The column to import from the CSV.
        db_column_name: The column to replace in the DB.
        database_path: Path to the SQLite database.
    """
    # Load the column from CSV
    df = read_csv(csv_path, usecols=["UNIQUEID", csv_column_name])
    
    if df[csv_column_name].isnull().any():
        print(f"Warning: Missing values found in column '{csv_column_name}'")

    # Connect to database
    engine = create_engine(f"sqlite:///{database_path}")
    Session = sessionmaker(bind=engine)
    session = Session()

    try:
        for _, row in df.iterrows():
            stmt = (
                update(Profile)
                .where(Profile.uniqueid == row["UNIQUEID"])
                .values({db_column_name: row[csv_column_name]})
            )
            session.execute(stmt)

        session.commit()
        print(f"Column '{db_column_name}' successfully reimported from {csv_path} : {csv_column_name}")

    except Exception as e:
        session.rollback()
        print(f"Error during update: {e}")
    finally:
        session.close()

def compare_csv_to_db_column( csv_path: str, session: Session, model: Type, id_column: str, field_column: str,
                              csv_id_column: str, csv_field_column: str ) -> dict[str, list[str]] :
    """
    Compare a specific column between a CSV file and a SQLAlchemy database table.

    Args :
        csv_path (str) : Path to the CSV file.
        session (Session) : SQLAlchemy session.
        model (Type) : SQLAlchemy model class.
        id_column (str) : Name of the unique identifier column (model).
        field_column (str) : Name of the column to compare (model).
        csv_id_column (str) : Name of the unique identifier column (csv file).
        csv_field_column (str) : Name of the column to compare (csv file).

    Returns :
        dict[str, list[str]]: Dictionary mapping unique_id -> [csv_value, db_value]
                              where the values differ.
    """
    
    with open(csv_path, newline='', encoding="utf-8") as f :
        reader = csv.DictReader(f)
        csv_data = {row[csv_id_column]: row[csv_field_column] for row in reader if row.get(csv_id_column) and row.get(csv_field_column)}

    # Query all matching db rows in one go
    ids = list(csv_data.keys())
    stmt = select(getattr(model, id_column), getattr(model, field_column)).where(getattr(model, id_column).in_(ids))
    results = session.execute(stmt).all()
    db_results = {
        str(getattr(row, id_column)): str(getattr(row, field_column))
        for row in results
    }

    # Compare and collect mismatches
    differences = {}
    for uid, csv_val in csv_data.items() :
        db_val = db_results.get(uid)
        if db_val is not None and str(csv_val).strip() != str(db_val).strip() :
            differences[uid] = [csv_val, db_val]

    return differences